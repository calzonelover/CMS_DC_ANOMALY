\chapter*{\Large \center Abstract}

% Guidance of how to write an abstract/summary provided by Nature: https://cbs.umn.edu/sites/cbs.umn.edu/files/public/downloads/Annotated_Nature_abstract.pdf

Compact Muon Solenoid (CMS) detector was built in the middle of collision from Large Hadron Collider (LHC) which is one of the most particle accelerator in the world. The mission is to collect the product from collision and decaying which happens 40 million times each second.
The data taking in CMS experiment is reconstructed to become physics quantity 48 hours after collision. The certification of data quality is made on run and lumisection levels. The criteria to certify are both from an automatic system as well as mannual work from untracable misbehaving of detector which are marked by offline shifer and detector experts.
Approximately 95\% of data are good and the rest of them are bad. The phenomenon that cause the data be marked as bad aer still not well known.
Then the aim of this work is to reduce the mannual work for data qualification by exploiding various types of semi-supervised leaning by treating the outlier as bad in lumisection granularity.